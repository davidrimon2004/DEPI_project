{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13830526,"sourceType":"datasetVersion","datasetId":8485735}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":2341.31638,"end_time":"2025-11-15T15:56:10.576064","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-11-15T15:17:09.259684","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"f33897d2-2f7d-4869-a3f7-e3a7534ad4c7","cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/code/davidhalim2004/data-cleaning?scriptVersionId=280113860\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{}},{"id":"c1953a70","cell_type":"markdown","source":"# Library importing","metadata":{"papermill":{"duration":0.004092,"end_time":"2025-11-15T15:17:13.280769","exception":false,"start_time":"2025-11-15T15:17:13.276677","status":"completed"},"tags":[]}},{"id":"69c9f35e","cell_type":"code","source":"!pip install xgboost\nimport pandas as pd\nimport joblib\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import train_test_split\nimport gc","metadata":{"_cell_guid":"c937e31b-4b1f-40d1-8db4-c9dfc4b99b42","_kg_hide-output":true,"_uuid":"01f2ca21-b4c1-4e8d-b532-36804b5cc32e","papermill":{"duration":3.178828,"end_time":"2025-11-15T15:17:16.462859","exception":false,"start_time":"2025-11-15T15:17:13.284031","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T20:08:16.652397Z","iopub.execute_input":"2025-11-22T20:08:16.652708Z","iopub.status.idle":"2025-11-22T20:08:20.643063Z","shell.execute_reply.started":"2025-11-22T20:08:16.652668Z","shell.execute_reply":"2025-11-22T20:08:20.642333Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.0.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->xgboost) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->xgboost) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->xgboost) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->xgboost) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->xgboost) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"id":"a80410d5","cell_type":"markdown","source":"# data pre-proccessing","metadata":{"papermill":{"duration":0.002693,"end_time":"2025-11-15T15:17:16.468906","exception":false,"start_time":"2025-11-15T15:17:16.466213","status":"completed"},"tags":[]}},{"id":"43761ece","cell_type":"markdown","source":"## data reading","metadata":{"papermill":{"duration":0.002722,"end_time":"2025-11-15T15:17:16.474405","exception":false,"start_time":"2025-11-15T15:17:16.471683","status":"completed"},"tags":[]}},{"id":"5fff65ca","cell_type":"code","source":"chunks = pd.read_csv(\"/kaggle/input/depi-dataset/data.csv\", chunksize=5_000_000)\nfinal_data = pd.concat(chunks, ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2025-11-22T20:08:20.644331Z","iopub.execute_input":"2025-11-22T20:08:20.644757Z","iopub.status.idle":"2025-11-22T20:09:28.006412Z","shell.execute_reply.started":"2025-11-22T20:08:20.644735Z","shell.execute_reply":"2025-11-22T20:09:28.005447Z"},"papermill":{"duration":156.478427,"end_time":"2025-11-15T15:19:52.955746","exception":false,"start_time":"2025-11-15T15:17:16.477319","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":2},{"id":"7310d266","cell_type":"code","source":"del chunks","metadata":{"execution":{"iopub.status.busy":"2025-11-22T20:09:28.007277Z","iopub.execute_input":"2025-11-22T20:09:28.007487Z","iopub.status.idle":"2025-11-22T20:09:28.011407Z","shell.execute_reply.started":"2025-11-22T20:09:28.007454Z","shell.execute_reply":"2025-11-22T20:09:28.010644Z"},"papermill":{"duration":0.008518,"end_time":"2025-11-15T15:19:52.967744","exception":false,"start_time":"2025-11-15T15:19:52.959226","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":3},{"id":"85c30992","cell_type":"code","source":"preprocessor=joblib.load(\"/kaggle/input/depi-dataset/pre-proccess.pkl\")","metadata":{"execution":{"iopub.status.busy":"2025-11-22T20:09:28.012573Z","iopub.execute_input":"2025-11-22T20:09:28.012829Z","iopub.status.idle":"2025-11-22T20:09:28.029350Z","shell.execute_reply.started":"2025-11-22T20:09:28.012811Z","shell.execute_reply":"2025-11-22T20:09:28.028716Z"},"papermill":{"duration":0.034901,"end_time":"2025-11-15T15:19:53.005592","exception":false,"start_time":"2025-11-15T15:19:52.970691","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator OrdinalEncoder from version 1.7.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\nhttps://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MinMaxScaler from version 1.7.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\nhttps://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 1.7.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\nhttps://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator ColumnTransformer from version 1.7.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\nhttps://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n  warnings.warn(\n","output_type":"stream"}],"execution_count":4},{"id":"50327ac1","cell_type":"markdown","source":"## Data spliting","metadata":{"papermill":{"duration":0.002847,"end_time":"2025-11-15T15:19:53.01164","exception":false,"start_time":"2025-11-15T15:19:53.008793","status":"completed"},"tags":[]}},{"id":"f90d900c-46e9-4347-b971-c91066dbb0ed","cell_type":"code","source":"store_models = {}\n\nstores = final_data[\"store_id\"].unique()\n\nfor store in stores:\n    print(f\"\\n==== Training model for store: {store} ====\")\n\n    # 1️⃣ Filter the data of that store only\n    df_store = final_data[final_data[\"store_id\"] == store].copy()\n\n    # 2️⃣ Split into X, y\n    X = df_store.drop(columns=[\"sales\"])\n    y = df_store[\"sales\"]\n    X=preprocessor.fit_transform(X)\n\n    # 3️⃣ Random Split for THIS store ONLY\n    X_temp, X_test, y_temp, y_test = train_test_split(\n        X, y, test_size=0.20, random_state=42\n    )\n    X_train, X_val, y_train, y_val = train_test_split(\n        X_temp, y_temp, test_size=0.15, random_state=42\n    )\n\n    # 4️⃣ Fit model\n    model = XGBRegressor(\n    objective='reg:tweedie',\n    tweedie_variance_power=1.35,\n    booster='gbtree',\n    device='cuda',\n    tree_method='hist',\n    random_state=42,\n    eval_metric='mae',\n    learning_rate=0.03,\n    max_depth=6,\n    min_child_weight=15,\n    subsample=0.7,\n    colsample_bytree=0.7,\n    reg_lambda=6,\n    reg_alpha=2,\n    n_estimators=3500,\n    early_stopping_rounds=40,\n    gamma= 1,\n    max_delta_step = 1\n    )\n    \n    model.fit(\n        X_train, y_train,\n        eval_set=[(X_val, y_val)],\n        verbose = False\n    )\n    model.score(X_train,y_train) , model.score(X_test,y_test)\n    from sklearn.metrics import mean_absolute_error, r2_score\n\n    train_mae = mean_absolute_error(y_train, model.predict(X_train))\n    test_mae  = mean_absolute_error(y_test,  model.predict(X_test))\n    train_r2  = r2_score(y_train, model.predict(X_train))\n    test_r2   = r2_score(y_test,  model.predict(X_test))\n\n    print(f\"MAE train: {train_mae:.4f}, test: {test_mae:.4f}\")\n    print(f\"R2  train: {train_r2:.4f}, test: {test_r2:.4f}\")\n   \n    # 5️⃣ Save model\n    store_models[store] = model\n    print(f\"Model for {store} trained and stored.\")\n\n    del X, y, X_temp, X_test, X_val, X_train, y_train, y_temp, y_test\n    gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T20:49:46.986002Z","iopub.execute_input":"2025-11-22T20:49:46.986743Z","iopub.status.idle":"2025-11-22T21:16:01.747965Z","shell.execute_reply.started":"2025-11-22T20:49:46.986717Z","shell.execute_reply":"2025-11-22T21:16:01.746969Z"},"_kg_hide-output":false},"outputs":[{"name":"stdout","text":"\n==== Training model for store: CA_1 ====\nMAE train: 0.4487, test: 0.4601\nR2  train: 0.8951, test: 0.8655\nModel for CA_1 trained and stored.\n\n==== Training model for store: CA_2 ====\nMAE train: 0.3590, test: 0.3680\nR2  train: 0.8510, test: 0.8240\nModel for CA_2 trained and stored.\n\n==== Training model for store: CA_3 ====\nMAE train: 0.6177, test: 0.6324\nR2  train: 0.9091, test: 0.8963\nModel for CA_3 trained and stored.\n\n==== Training model for store: CA_4 ====\nMAE train: 0.2630, test: 0.2703\nR2  train: 0.8514, test: 0.8221\nModel for CA_4 trained and stored.\n\n==== Training model for store: TX_1 ====\nMAE train: 0.3370, test: 0.3487\nR2  train: 0.8966, test: 0.8404\nModel for TX_1 trained and stored.\n\n==== Training model for store: TX_2 ====\nMAE train: 0.4124, test: 0.4236\nR2  train: 0.9176, test: 0.8962\nModel for TX_2 trained and stored.\n\n==== Training model for store: TX_3 ====\nMAE train: 0.3586, test: 0.3697\nR2  train: 0.9099, test: 0.8878\nModel for TX_3 trained and stored.\n\n==== Training model for store: WI_1 ====\nMAE train: 0.3178, test: 0.3256\nR2  train: 0.8635, test: 0.8487\nModel for WI_1 trained and stored.\n\n==== Training model for store: WI_2 ====\nMAE train: 0.3982, test: 0.4149\nR2  train: 0.8883, test: 0.8643\nModel for WI_2 trained and stored.\n\n==== Training model for store: WI_3 ====\nMAE train: 0.3703, test: 0.3851\nR2  train: 0.9128, test: 0.8841\nModel for WI_3 trained and stored.\n","output_type":"stream"}],"execution_count":9},{"id":"0035d8ee-ffa7-4dea-aa6f-c69d2c83fd29","cell_type":"code","source":"import numpy as np\nfor store in stores:\n    # 1️⃣ Filter the data of that store only\n    df_store = final_data[final_data[\"store_id\"] == store].copy()\n\n    # 2️⃣ Split into X, y\n    X = df_store.drop(columns=[\"sales\"])\n    y = df_store[\"sales\"]\n    X=preprocessor.fit_transform(X)\n\n    # 3️⃣ Random Split for THIS store ONLY\n    X_temp, X_test, y_temp, y_test = train_test_split(\n        X, y, test_size=0.20, random_state=42\n    )\n    X_train, X_val, y_train, y_val = train_test_split(\n        X_temp, y_temp, test_size=0.15, random_state=42\n    )\n    y_pred = store_models[store].predict(X_test)\n    # Round predictions and ground truth\n    y_pred_rounded = np.round(y_pred).astype(int)\n    y_test_rounded = np.round(y_test).astype(int)\n\n    print(\"\\n=== Sample Predictions vs Actuals ===\\n\")\n    for i in range(min(25, len(y_test))):\n        print(f\"Pred: {y_pred_rounded[i]:>3}   Actual: {y_test_rounded.iloc[i]:>3}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T21:24:45.299222Z","iopub.execute_input":"2025-11-22T21:24:45.299841Z","iopub.status.idle":"2025-11-22T21:27:07.677904Z","shell.execute_reply.started":"2025-11-22T21:24:45.299814Z","shell.execute_reply":"2025-11-22T21:27:07.677228Z"}},"outputs":[{"name":"stdout","text":"\n=== Sample Predictions vs Actuals ===\n\nPred:   2   Actual:   3\nPred:   2   Actual:   2\nPred:  11   Actual:   8\nPred:   3   Actual:   3\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   2   Actual:   2\nPred:   6   Actual:   6\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   2   Actual:   2\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   3   Actual:   3\nPred:   6   Actual:   6\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   2   Actual:   2\nPred:   0   Actual:   0\nPred:   0   Actual:   0\n\n=== Sample Predictions vs Actuals ===\n\nPred:   0   Actual:   0\nPred:   3   Actual:   3\nPred:  15   Actual:   6\nPred:   2   Actual:   0\nPred:   1   Actual:   1\nPred:   2   Actual:   3\nPred:   0   Actual:   0\nPred:   1   Actual:   1\nPred:   2   Actual:   1\nPred:   1   Actual:   1\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   2   Actual:   2\nPred:   0   Actual:   0\nPred:   1   Actual:   1\nPred:   0   Actual:   2\nPred:   0   Actual:   0\nPred:   0   Actual:   0\n\n=== Sample Predictions vs Actuals ===\n\nPred:   3   Actual:   4\nPred:   0   Actual:   0\nPred:  17   Actual:  11\nPred:   2   Actual:   3\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   2   Actual:   3\nPred:   2   Actual:   2\nPred:   6   Actual:   4\nPred:   0   Actual:   0\nPred:   1   Actual:   3\nPred:   0   Actual:   0\nPred:   3   Actual:   4\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   5   Actual:   5\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   7   Actual:  14\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   2   Actual:   2\n\n=== Sample Predictions vs Actuals ===\n\nPred:   1   Actual:   1\nPred:   2   Actual:   3\nPred:   5   Actual:   5\nPred:   1   Actual:   1\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   1   Actual:   2\nPred:   0   Actual:   0\nPred:   1   Actual:   1\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   1   Actual:   1\nPred:   0   Actual:   0\nPred:   1   Actual:   1\nPred:   2   Actual:   1\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   1   Actual:   2\nPred:   0   Actual:   0\nPred:   1   Actual:   1\nPred:   0   Actual:   3\n\n=== Sample Predictions vs Actuals ===\n\nPred:   6   Actual:   3\nPred:   2   Actual:   1\nPred:  12   Actual:  10\nPred:   4   Actual:   5\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   1   Actual:   1\nPred:   2   Actual:   3\nPred:   5   Actual:  10\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   2   Actual:   1\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   1   Actual:   1\nPred:   0   Actual:   0\nPred:   1   Actual:   1\nPred:   5   Actual:   8\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\n\n=== Sample Predictions vs Actuals ===\n\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   8   Actual:  24\nPred:   4   Actual:   5\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   7   Actual:   3\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   1   Actual:   2\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   2   Actual:   3\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   2   Actual:   1\nPred:   3   Actual:   2\nPred:   0   Actual:   0\n\n=== Sample Predictions vs Actuals ===\n\nPred:   0   Actual:   0\nPred:   3   Actual:   5\nPred:   8   Actual:   6\nPred:   2   Actual:   3\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   2   Actual:   4\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   1   Actual:   1\nPred:   3   Actual:   3\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   2   Actual:   3\nPred:   0   Actual:   0\nPred:   1   Actual:   1\nPred:   2   Actual:   1\nPred:   2   Actual:   2\nPred:   0   Actual:   0\n\n=== Sample Predictions vs Actuals ===\n\nPred:   0   Actual:   0\nPred:   2   Actual:   3\nPred:   3   Actual:   7\nPred:   1   Actual:   1\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   1   Actual:   1\nPred:   1   Actual:   1\nPred:   1   Actual:   2\nPred:   0   Actual:   0\nPred:   2   Actual:   1\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   2   Actual:   3\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\n\n=== Sample Predictions vs Actuals ===\n\nPred:   0   Actual:   0\nPred:   8   Actual:   5\nPred:  13   Actual:  14\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   2   Actual:   2\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   1   Actual:   1\nPred:   0   Actual:   0\nPred:   1   Actual:   1\nPred:   0   Actual:   0\nPred:   2   Actual:   3\nPred:   2   Actual:   3\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\n\n=== Sample Predictions vs Actuals ===\n\nPred:   3   Actual:   4\nPred:   3   Actual:   3\nPred:   6   Actual:   4\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   1   Actual:   1\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   1\nPred:   1   Actual:   1\nPred:   0   Actual:   0\nPred:   2   Actual:   2\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   1   Actual:   1\nPred:   3   Actual:   5\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\nPred:   0   Actual:   0\n","output_type":"stream"}],"execution_count":11},{"id":"284c4d08-e8a6-48e6-beb5-1b323dae2a23","cell_type":"code","source":"for i in store_models.keys():\n    joblib.dump(store_models[i], f\"/kaggle/working/{i}.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T21:32:15.006429Z","iopub.execute_input":"2025-11-22T21:32:15.006815Z","iopub.status.idle":"2025-11-22T21:32:15.832921Z","shell.execute_reply.started":"2025-11-22T21:32:15.006794Z","shell.execute_reply":"2025-11-22T21:32:15.832305Z"}},"outputs":[],"execution_count":13},{"id":"57b388d7-7cb3-4ec0-bb08-608c0b61802e","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}